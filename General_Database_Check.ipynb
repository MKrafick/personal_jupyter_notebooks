{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ee25e0",
   "metadata": {},
   "source": [
    "## Notebook: SW-General_Database_Check\n",
    "\n",
    "#### Abstract\n",
    "The purpose of this notebook is to run a generic database health check. This does not look for specific archetecture pre-requisites per se. The notebook does try to gather data for general healh, best practices, and key performance indicators. Various SQL was taken from other Jupyter Notebooks written by Ember Crooks or other performance and tuning articles, blogs, and resources. Various links to these methods are at the end of the notebook in the \"Credit and References\" section.\n",
    "\n",
    "#### To Use This Notebook\n",
    "- If the libraries have not been installed, you will need to manually excute the *Install Notebook Prerequisites* section and restart the kernel.\n",
    "- At a minimum you will need to manually *Import the Notebook Prerequisites* to load the libraries needed (this needs to be done only once after the notebook is opened that specific time). \n",
    "- A variable file with connectivity information is expected to be held in the parent directory.\n",
    "- Manually run the *Establish Database Connection*, type the password, and hit enter. \n",
    "- Once done you can select the next section and choose \"Cells\" from the menu bar and then \"Run all Below\".\n",
    "- Note: The SQL/Code cells are hidden to make it easier to read the generated output. You can turn that off and on in the next section. I reccomend exposing the SQL untill the whole notebook runs and then I would toggle off the SQL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac165c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00c2e8",
   "metadata": {},
   "source": [
    "## Code Toggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d83f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hide code cells\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<i><b>The raw code for this IPython notebook is by default hidden for easier reading.</b><br><br>\n",
    "To see view the queries used in this notebook, you will need to toggle on/off the raw code, by clicking <a href=\"javascript:code_toggle()\">here</a>.</i>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd11f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0daeb",
   "metadata": {},
   "source": [
    "## Install Notebook Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f268497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this notebook is running on a Windows based machine with a Db2 client, you will need to run\n",
    "# the following to allow you to run Db2 commands (i.e. db2exfmt) not basic SQL\n",
    "\n",
    "import sys,os,os.path\n",
    "os.environ['IBM_DB_HOME']='/Applications/dsdriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31798e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not installed the following libraries in Python already (command line or via a notebook),\n",
    "# you should run the following statements.\n",
    "\n",
    "# Load importlib to give yourself the ability to import details from Python to see if certian libraries exist.\n",
    "# !pip3 install importlib     #Import library\n",
    "import importlib\n",
    "\n",
    "# The following will check for ibm_db_sa as a litmus test. If it exists, we assume the other libraries are installed.\n",
    "# If it does not exist, install the libraries.\n",
    "\n",
    "spec = importlib.util.find_spec(\"ibm_db_sa\")\n",
    "if spec is None:\n",
    "    print(\"Installing prerequisites.\")\n",
    "    # Dependancy: ipython-sql -> sqlalchemy -> ibm_db_sa -> ibm_db\n",
    "    !pip3 install ipython-sql #SQL Magic (%sql) using SQLAlchemy connect strings\n",
    "    !pip3 install ibm_db      #Db2 API for Python\n",
    "    !pip3 install ibm_db_sa   #Db2 adaptor for SQLAlchemy\n",
    "    !pip3 install matplotlib  #Plotting library for visualizations\n",
    "    !pip3 install pandas      #Data analysis and manipulation\n",
    "    \n",
    "    # Unnofficial community extentions, creates a new tab in Jupyter Notebook\n",
    "    # Uncheck \"disable configuration for nbextensions without explicit compatibility\" within new tab\n",
    "    !pip3 install https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tarball/master\n",
    "    !jupyter contrib nbextension install --user\n",
    "    print()\n",
    "else:\n",
    "    print(\"Prerequisites already met.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c7c29",
   "metadata": {},
   "source": [
    "## Import Notebook Perequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6171bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules and load SQL Magic\n",
    "import ibm_db\n",
    "import ibm_db_sa\n",
    "import sqlalchemy\n",
    "%load_ext sql\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Markdown\n",
    "#import nbextensions\n",
    "%matplotlib inline\n",
    "import getpass\n",
    "\n",
    "# Configure SQL Magic in a few nice ways\n",
    "%config SqlMagic.style = 'MSWORD_FRIENDLY'\n",
    "pd.set_option('display.max_rows', 4096)\n",
    "pd.set_option('display.max_columns', 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69784ea9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adaf388",
   "metadata": {},
   "source": [
    "## Establish Target Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filename for passwords\n",
    "filename = 'ember_variables.py'\n",
    "# source the file\n",
    "%run ../$filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to target Db2 database\n",
    "\n",
    "# Connection Details\n",
    "inst=OMS10_inst['PROD']\n",
    "user=OMS10_user['PROD']\n",
    "host=OMS10_host['PROD']\n",
    "schema='OMSUSR'  # Not necessary for connection, but used later to focus target of SQL\n",
    "db=OMS10_db['PROD']\n",
    "port=OMS10_port['PROD']\n",
    "\n",
    "# Prompt for Password\n",
    "password = getpass.getpass('Enter password for '+user)\n",
    "import urllib\n",
    "password = urllib.parse.quote(password) #Use to handle special characters\n",
    "\n",
    "# Connection String\n",
    "%sql db2+ibm_db://$user:$password@$host:$port/$db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d6ee3f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1d334",
   "metadata": {},
   "source": [
    "## Server Level Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ef4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_server << \n",
    "SELECT \n",
    "    HOST_NAME,\n",
    "    OS_NAME AS OS,\n",
    "    OS_FULL_VERSION AS OS_VERSION,\n",
    "    OS_ARCH_TYPE,\n",
    "    CPU_ONLINE AS CPU,\n",
    "    CPU_CORES_PER_SOCKET AS CORES_PER_SOCKET,\n",
    "    MEMORY_TOTAL AS MEMORY,\n",
    "    MEMORY_SWAP_TOTAL AS SWAP,\n",
    "    MEMORY_SWAP_FREE AS SWAP_FREE\n",
    "FROM TABLE(SYSPROC.ENV_GET_SYSTEM_RESOURCES()) AS T\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736833ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Server Details\"))\n",
    "display(Markdown(\"Tip: Is swap space 1-2x the size of dedicated memory?\"))\n",
    "db_server_df=db_server.DataFrame()\n",
    "db_server_df.columns=db_server_df.columns.str.upper()\n",
    "db_server_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c9bb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8db12",
   "metadata": {},
   "source": [
    "## Db2 Version and Licensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda05ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_ver << \n",
    "SELECT \n",
    "    INST_NAME, \n",
    "    SERVICE_LEVEL, \n",
    "    BLD_LEVEL, \n",
    "    FIXPACK_NUM \n",
    "FROM SYSIBMADM.ENV_INST_INFO \n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14469926",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Db2 Database Version\"))\n",
    "db_ver_df=db_ver.DataFrame()\n",
    "db_ver_df.columns=db_ver_df.columns.str.upper()\n",
    "db_ver_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607aa93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_license << \n",
    "SELECT \n",
    "    INSTALLED_PROD, \n",
    "    INSTALLED_PROD_FULLNAME, \n",
    "    LICENSE_INSTALLED ,\n",
    "    PROD_RELEASE ,\n",
    "    LICENSE_TYPE \n",
    "FROM SYSIBMADM.ENV_PROD_INFO \n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db199efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Db2 Licensing\"))\n",
    "db_license_df=db_license.DataFrame()\n",
    "db_license_df.columns=db_license_df.columns.str.upper()\n",
    "db_license_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786395f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66faeb",
   "metadata": {},
   "source": [
    "## Metrics by Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a714e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql instance_uptime <<\n",
    "SELECT \n",
    "    VARCHAR_FORMAT(DB2START_TIME, 'YYYY-MM-DD HH24:MM:SS') AS INSTANCE_ACTIVATION\n",
    "    FROM TABLE(MON_GET_INSTANCE(-2))\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e6e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Db2 Instance Start time\"))\n",
    "instance_uptime_df=instance_uptime.DataFrame()\n",
    "instance_uptime_df.columns=instance_uptime_df.columns.str.upper()\n",
    "instance_uptime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f745b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_env_settings <<\n",
    "SELECT \n",
    "  REG_VAR_NAME AS DB2SET_PARM, \n",
    "  REG_VAR_VALUE AS DB2SET_VALUE\n",
    "FROM TABLE(ENV_GET_REG_VARIABLES(-1, 1)) \n",
    "WHERE REG_VAR_NAME IN ('DB2COMM','DB2AUTH','DB2_PARALLEL_IO','DB2_RESTORE_GRANT_ADMIN_AUTHORITIES','AUTOSTART')\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Common Db2 Environment Settings To Review For Best Practice\"))\n",
    "db_env_settings_df=db_env_settings.DataFrame()\n",
    "db_env_settings_df.columns=db_env_settings_df.columns.str.upper()\n",
    "db_env_settings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20919dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql mon_settings <<\n",
    "SELECT \n",
    "  NAME AS MONITOR_VALUE,\n",
    "  VALUE AS IS_ON\n",
    "FROM SYSIBMADM.DBMCFG\n",
    "WHERE NAME IN ('dft_mon_bufpool','dft_mon_lock','dft_mon_sort','dft_mon_stmt','dft_mon_table','dft_mon_timestamp','dft_mon_uow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b984f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Are Database Metrics Being Monitored (DBM CFG)?\"))\n",
    "mon_settings_df=mon_settings.DataFrame()\n",
    "mon_settings_df.columns=mon_settings_df.columns.str.upper()\n",
    "mon_settings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc54c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql key_dbm_config <<\n",
    "SELECT \n",
    "  NAME AS DBM_VALUE,\n",
    "  VALUE AS CURRENT_SETTING\n",
    "FROM SYSIBMADM.DBMCFG\n",
    "WHERE NAME IN ('svcename','dftdbpath','diagpath','instance_memory','intra_parallel','keystore_type','keystore_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d727c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Key Database Manager Settings (DBM CFG)\"))\n",
    "key_dbm_config_df=key_dbm_config.DataFrame()\n",
    "key_dbm_config_df.columns=key_dbm_config_df.columns.str.upper()\n",
    "key_dbm_config_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b86877",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ce236",
   "metadata": {},
   "source": [
    "## Metrics by Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819adb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql database_uptime <<\n",
    "SELECT\n",
    "VARCHAR_FORMAT(DB_CONN_TIME, 'YYYY-MM-DD HH24:MM:SS') AS DATABASE_ACTIVATION\n",
    "    FROM TABLE(MON_GET_DATABASE(-2))\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9391cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Database Start time\"))\n",
    "display(Markdown(\"Note: Many notebook calculations use cumulative database metrics collected from database start time. You could be looking at 2 days or 2 years of information. Metrics will change on database restart, which will reset the cumulative data.\"))\n",
    "database_uptime_df=database_uptime.DataFrame()\n",
    "database_uptime_df.columns=database_uptime_df.columns.str.upper()\n",
    "database_uptime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_last_bkup <<\n",
    "SELECT VARCHAR_FORMAT(LAST_BACKUP, 'YYYY-MM-DD HH24:MM:SS') AS LAST_DATABASE_BACKUP\n",
    "    FROM TABLE(MON_GET_DATABASE(-2))\n",
    "WITH UR;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Last Database Backup\"))\n",
    "db_last_bkup_df=db_last_bkup.DataFrame()\n",
    "db_last_bkup_df.columns=db_last_bkup_df.columns.str.upper()\n",
    "db_last_bkup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql key_db_cfg << \n",
    "SELECT \n",
    "  NAME AS DB_VALUE,\n",
    "  VALUE AS CURRENT_SETTING\n",
    "FROM SYSIBMADM.DBCFG \n",
    "WHERE NAME IN ('database_memory','locktimeout','logarchmeth1','logfilsiz','logprimary','logsecond','numlogspan','logarchcompr1','self_tuning_mem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b76af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Key Database Settings (DB CFG)\"))\n",
    "key_db_cfg_df=key_db_cfg.DataFrame()\n",
    "key_db_cfg_df.columns=key_db_cfg_df.columns.str.upper()\n",
    "key_db_cfg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a526a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_arss <<\n",
    "SELECT \n",
    "\tROWS_RETURNED,\n",
    "\tSELECT_SQL_STMTS,\n",
    "\tCASE \n",
    "\t\tWHEN SELECT_SQL_STMTS > 0 \n",
    "\t\t\tTHEN DECIMAL(FLOAT(rows_returned)/FLOAT(SELECT_SQL_STMTS),10,2)\n",
    "\t\t\tELSE 'No Div. By zero'\n",
    "\tEND AS AVG_RESULT_SET_SIZE,\n",
    "\tCASE \n",
    "\t\tWHEN DECIMAL(FLOAT(rows_returned)/FLOAT(SELECT_SQL_STMTS),10,2) <= 10 \n",
    "\t\t\tTHEN 'Transaction Processing Like Workload' \n",
    "\t\t\tELSE 'Warehouse Like Workload'\n",
    "\tEND AS WORKLOAD_TYPE\n",
    "FROM TABLE(MON_GET_DATABASE(-2))\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Database Average Result Set Size (ARSS)\"))\n",
    "display(Markdown(\"Tip: DB ARSS for OLTP < 10 | DB ARSS for DW > 10\"))\n",
    "db_arss_df=db_arss.DataFrame()\n",
    "db_arss_df.columns=db_arss_df.columns.str.upper()\n",
    "db_arss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df53bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_ixref <<\n",
    "SELECT ROWS_READ, \n",
    " ROWS_RETURNED,\n",
    " ROWS_READ/ROWS_RETURNED AS IXREF \n",
    "FROM TABLE(MON_GET_WORKLOAD('',-2)) AS T \n",
    "WHERE WORKLOAD_NAME='SYSDEFAULTUSERWORKLOAD' \n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Database Index Read Efficiency (IXREF)\"))\n",
    "display(Markdown(\"Tip: (OLTP)  <10 Ideal | 10-100 Potentially Acceptiable  | 100-1000 Poor | >1000 Bad\"))\n",
    "db_ixref_df=db_ixref.DataFrame()\n",
    "db_ixref_df.columns=db_ixref_df.columns.str.upper()\n",
    "db_ixref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_rollbackpercent <<\n",
    "SELECT TOTAL_APP_COMMITS AS APP_COMMITS, \n",
    "\t   TOTAL_APP_ROLLBACKS AS APP_ROLLBACKS,\n",
    "\t   TOTAL_APP_COMMITS + TOTAL_APP_ROLLBACKS AS TOTAL,\n",
    "\t   CASE\n",
    "            WHEN TOTAL_APP_COMMITS + TOTAL_APP_ROLLBACKS > 0 THEN\n",
    "                DECIMAL(FLOAT(TOTAL_APP_ROLLBACKS)/FLOAT(TOTAL_APP_COMMITS + TOTAL_APP_ROLLBACKS),10,2)*100\n",
    "            ELSE 0\n",
    "        END AS PCNT_ROLLBACK\n",
    "FROM TABLE(MON_GET_DATABASE(-2))\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Database Transaction Rollback Percentage\"))\n",
    "display(Markdown(\"Tip: Percentage of your hardware is wasting time on transactions that never complete. Anything over 1% would be uncommon. Can lead to locking and contention in database.\"))\n",
    "db_rollbackpercent_df=db_rollbackpercent.DataFrame()\n",
    "db_rollbackpercent_df.columns=db_rollbackpercent_df.columns.str.upper()\n",
    "db_rollbackpercent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_rollback= %sql SELECT TOTAL_APP_COMMITS AS APP_COMMITS, \\\n",
    "\tTOTAL_APP_ROLLBACKS AS APP_ROLLBACKS \\\n",
    "FROM TABLE(MON_GET_DATABASE(-2)) \\\n",
    "WITH UR\n",
    "\n",
    "db_rollback_df=db_rollback.DataFrame()\n",
    "db_rollback_df.sum().plot(kind='pie', autopct='%1.0f%%', ylabel=\" \", title='Percent of Database Rollbacks')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f292f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0706a8",
   "metadata": {},
   "source": [
    "## Metrics by Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql table_byreadoverflow << \n",
    "WITH t AS (\n",
    " SELECT\n",
    "      TABSCHEMA AS SCHEMA,\n",
    "      TABNAME AS TABLE,\n",
    "      ROWS_READ,\n",
    "      OVERFLOW_ACCESSES,\n",
    "      CASE WHEN ROWS_READ > 0 \n",
    "        THEN DECIMAL(FLOAT(OVERFLOW_ACCESSES)/FLOAT(ROWS_READ),10,2)*100 \n",
    "        ELSE 0 \n",
    "      END AS R_OVRFLW_PCT\n",
    " FROM TABLE(MON_GET_TABLE('','',-2)) AS t WHERE TABSCHEMA =:schema AND OVERFLOW_ACCESSES > 0)\n",
    "SELECT * FROM t WHERE R_OVRFLW_PCT >= 3 ORDER BY R_OVRFLW_PCT DESC\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Tables > 3% Read Overflows\"))\n",
    "display(Markdown(\"Tip: Read overflow over 3% is a signal to run a REORG. Db2 is looking for data where it expects to be and finds a pointer to a new location causing double logical read.\"))\n",
    "table_byreadoverflow_df=table_byreadoverflow.DataFrame()\n",
    "table_byreadoverflow_df.columns=table_byreadoverflow_df.columns.str.upper()\n",
    "table_byreadoverflow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql table_bywriteoverflow << \n",
    "WITH t AS (\n",
    " SELECT\n",
    "      TABSCHEMA AS SCHEMA,\n",
    "      TABNAME AS TABLE,\n",
    "      ROWS_UPDATED,\n",
    "      OVERFLOW_CREATES,\n",
    "      CASE WHEN ROWS_UPDATED > 0 \n",
    "        THEN DECIMAL(FLOAT(OVERFLOW_CREATES)/FLOAT(ROWS_UPDATED),10,2)*100 \n",
    "        ELSE 0 \n",
    "      END AS W_OVRFLW_PCT\n",
    " FROM TABLE(MON_GET_TABLE('','',-2)) AS t WHERE TABSCHEMA =:schema AND OVERFLOW_CREATES > 0)\n",
    "SELECT * FROM t WHERE W_OVRFLW_PCT >= 3 ORDER BY W_OVRFLW_PCT DESC\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Tables > 3% Write Overflows\"))\n",
    "display(Markdown(\"Tip: Write overflow over 3% is a signal to run a REORG. An update operation to VARCHAR causes the field to be longer and not fit on original data page. A pointer is left and the data is written on another page.\"))\n",
    "table_bywriteoverflow_df=table_bywriteoverflow.DataFrame()\n",
    "table_bywriteoverflow_df.columns=table_bywriteoverflow_df.columns.str.upper()\n",
    "table_bywriteoverflow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57eee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql table_top10_byinsert << \n",
    "SELECT * \n",
    "FROM (SELECT ROW_NUMBER() OVER(ORDER BY SUM(ROWS_INSERTED) DESC) AS RANK, \n",
    "       TRIM(TABSCHEMA) as SCHEMA, \n",
    "       TRIM(TABNAME) as TABLE, \n",
    "       SUM(ROWS_INSERTED) as ROWS_INSERTED\n",
    "      FROM TABLE(MON_GET_TABLE('','',-2)) AS TB\n",
    "      WHERE TABSCHEMA=:schema\n",
    "      GROUP BY TABSCHEMA, TABNAME) \n",
    "WHERE RANK<=10\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ad896",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Top 10 Tables by Rows Inserted\"))\n",
    "table_top10_byinsert_df=table_top10_byinsert.DataFrame()\n",
    "table_top10_byinsert_df.columns=table_top10_byinsert_df.columns.str.upper()\n",
    "table_top10_byinsert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql table_top10_byread << \n",
    "SELECT * \n",
    "FROM (SELECT ROW_NUMBER() OVER(ORDER BY SUM(ROWS_READ) DESC) AS RANK, \n",
    "       TRIM(TABSCHEMA) AS SCHEMA, \n",
    "       TRIM(TABNAME) AS TABLE, \n",
    "       SUM(ROWS_READ) AS ROWS_READ\n",
    "      FROM TABLE(MON_GET_TABLE('','',-2)) AS TB \n",
    "      WHERE TABSCHEMA=:schema\n",
    "      GROUP BY TABSCHEMA, TABNAME) \n",
    "WHERE RANK<=10\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f820774",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Top 10 Tables by Rows Read\"))\n",
    "table_top10_byread_df=table_top10_byread.DataFrame()\n",
    "table_top10_byread_df.columns=table_top10_byread_df.columns.str.upper()\n",
    "table_top10_byread_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql table_top10_byupdate <<\n",
    "SELECT * \n",
    "FROM (SELECT ROW_NUMBER() OVER(ORDER BY SUM(ROWS_UPDATED) DESC) AS RANK, \n",
    "       TRIM(TABSCHEMA) AS SCHEMA, \n",
    "       TRIM(TABNAME) AS TABNAME, \n",
    "       SUM(ROWS_UPDATED) AS ROWS_UPDATED\n",
    "      FROM TABLE(MON_GET_TABLE('','',-2)) AS TB \n",
    "      WHERE TABSCHEMA=:schema\n",
    "      GROUP BY TABSCHEMA, TABNAME) \n",
    "WHERE RANK<=10\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Top 10 Tables by Rows Updated\"))\n",
    "table_top10_byupdate_df=table_top10_byupdate.DataFrame()\n",
    "table_top10_byupdate_df.columns=table_top10_byupdate_df.columns.str.upper()\n",
    "table_top10_byupdate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4da361",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql table_top10_bydelete <<\n",
    "SELECT * \n",
    "FROM (SELECT ROW_NUMBER() OVER(ORDER BY SUM(ROWS_DELETED) DESC) AS RANK,\n",
    "       TRIM(TABSCHEMA) AS SCHEMA, \n",
    "       TRIM(TABNAME) AS NAME, \n",
    "       SUM(ROWS_DELETED) AS ROWS_DELETED\n",
    "      FROM TABLE(MON_GET_TABLE('','',-2)) AS TB\n",
    "      WHERE TABSCHEMA=:schema\n",
    "      GROUP BY TABSCHEMA, TABNAME) \n",
    "WHERE RANK<=10\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Top 10 Tables by Rows Deleted\"))\n",
    "table_top10_bydelete_df=table_top10_bydelete.DataFrame()\n",
    "table_top10_bydelete_df.columns=table_top10_bydelete_df.columns.str.upper()\n",
    "table_top10_bydelete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3542c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql table_top10_byscan <<\n",
    "SELECT * \n",
    "FROM (SELECT ROW_NUMBER() OVER(ORDER BY SUM(TABLE_SCANS) DESC) AS RANK, \n",
    "       TRIM(TABSCHEMA) AS SCHEMA, \n",
    "       TRIM(TABNAME) AS TABLE, \n",
    "       SUM(TABLE_SCANS) AS NUM_SCANS\n",
    "      FROM TABLE(MON_GET_TABLE('','',-2)) AS TB \n",
    "      GROUP BY TABSCHEMA, TABNAME) \n",
    "WHERE RANK<=10\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Top 10 Tables by Number of Scans\"))\n",
    "table_top10_byscan_df=table_top10_byscan.DataFrame()\n",
    "table_top10_byscan_df.columns=table_top10_byscan_df.columns.str.upper()\n",
    "table_top10_byscan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql top_lowcard_indexes <<\n",
    "\n",
    "-- Find top 25 busiest tables on 100 rows or more\n",
    "-- Calculate index cardinality percentage compared to total table cardinality\n",
    "-- Show index cardinality percentage less than to equal to 3%\n",
    "-- Do not take (U)nique indexes into account because they are used to enforce uniqueness\n",
    "\n",
    "SELECT A.TABSCHEMA AS SCHEMA,\n",
    "       A.TABNAME AS TABLE,\n",
    "       A.INDNAME AS INDEX_NAME,\n",
    "       B.CARD AS TB_CARD,\n",
    "       A.FULLKEYCARD AS IX_FULLKEYCARD,\n",
    "       INT((FLOAT(A.FULLKEYCARD)/FLOAT(B.CARD)) * 100) AS PCNT_TBCARD\n",
    "FROM SYSCAT.INDEXES A INNER JOIN SYSCAT.TABLES B\n",
    "       ON A.TABSCHEMA = B.TABSCHEMA\n",
    "       AND A.TABNAME = B.TABNAME\n",
    "WHERE A.FULLKEYCARD > 0\n",
    "     AND A.TABSCHEMA <> 'SYSIBM'\n",
    " \t AND B.CARD > 100\n",
    " \t AND A.UNIQUERULE <> 'U'\n",
    " \t AND INT((FLOAT(A.FULLKEYCARD)/FLOAT(B.CARD)) * 100) <= 3\n",
    " \t AND A.TABSCHEMA=:schema\n",
    " \t AND A.TABNAME IN \n",
    "\t   (SELECT TABNAME\n",
    "       FROM TABLE(MON_GET_TABLE('','',-2)) \n",
    "       WHERE TABSCHEMA=:schema\n",
    "       ORDER BY ROWS_INSERTED + ROWS_UPDATED + ROWS_DELETED DESC\n",
    "       FETCH FIRST 25 ROWS ONLY)\n",
    "ORDER BY INT((FLOAT(A.FULLKEYCARD)/FLOAT(B.CARD)) * 100) ASC, B.CARD DESC\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Low Cardinality Indexes (of Top 25 Busiest Tables)\"))\n",
    "display(Markdown(\"Tip: The higher the FULLKEYCARD is (in relation to table cardinality) the more unique the value is. This leads to an efficient index. The lower FULLKEYCARD value means less unique values (1 being all values the same) which causes an inefficient index.\"))\n",
    "top_lowcard_indexes_df=top_lowcard_indexes.DataFrame()\n",
    "top_lowcard_indexes_df.columns=top_lowcard_indexes_df.columns.str.upper()\n",
    "top_lowcard_indexes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql top_tables_unused_indexes <<\n",
    "SELECT\n",
    "\tTABSCHEMA,\n",
    "\tTABNAME,\n",
    "\tCOUNT(INDNAME) AS IDX_NOT_USED_CNT\n",
    "FROM SYSCAT.INDEXES\n",
    "WHERE LASTUSED='0001-01-01' AND tabschema=:schema\n",
    "AND TABNAME IN\n",
    " \t   (SELECT TABNAME\n",
    "       FROM TABLE(MON_GET_TABLE('','',-2))\n",
    "       WHERE TABSCHEMA=:schema\n",
    "       ORDER BY ROWS_INSERTED + ROWS_UPDATED + ROWS_DELETED DESC\n",
    "       FETCH FIRST 25 ROWS ONLY)\n",
    "GROUP BY TABSCHEMA,TABNAME\n",
    "ORDER BY IDX_NOT_USED_CNT DESC\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Number of Indexes That Have Never Been Used (of Top 25 Busiest Tables)\"))\n",
    "display(Markdown(\"Tip: The more indexes a table has, the more of a performance impact on INSERT operations. These tables have high write activity but have indexes that are never used and could be slowing down INSERT performance.\"))\n",
    "top_tables_unused_indexes_df=top_tables_unused_indexes.DataFrame()\n",
    "top_tables_unused_indexes_df.columns=top_tables_unused_indexes_df.columns.str.upper()\n",
    "top_tables_unused_indexes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14555cce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a6efc",
   "metadata": {},
   "source": [
    "## Metrics by Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e3c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql stmt_top10_byixref <<\n",
    "WITH SUM_TAB (SUM_RR) AS (\n",
    "        SELECT FLOAT(SUM(ROWS_READ))\n",
    "        FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T)\n",
    "SELECT\n",
    "        INSERT_TIMESTAMP AS FIRST_INSRT_INTO_CACHE,\n",
    "        SUBSTR(STMT_TEXT,1,50) AS STATEMENT,\n",
    "        ROWS_READ,\n",
    "        DECIMAL(100*(FLOAT(ROWS_READ)/SUM_TAB.SUM_RR),5,2) AS PCT_TOT_RR,\n",
    "        ROWS_RETURNED,\n",
    "        CASE\n",
    "            WHEN ROWS_RETURNED > 0 THEN\n",
    "                DECIMAL(FLOAT(ROWS_READ)/FLOAT(ROWS_RETURNED),10,2)\n",
    "            ELSE -1\n",
    "        END AS IXREF,\n",
    "        NUM_EXECUTIONS\n",
    "    FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T, SUM_TAB\n",
    "    ORDER BY ROWS_READ DESC FETCH FIRST 10 ROWS ONLY \n",
    "    WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae42c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Top 10 Inefficient Statements (IXREF)\"))\n",
    "display(Markdown(\"Tip: Index Read Efficiency shows how many rows are scanned to fetch the row DB2 needs. Ideally in a OLTP environment this should be <10. High IXREF SQL that executes frequently could be a performance problem. Keep in mind, the timestamp of first insert into package cache can change on rerun as things are flushed out, etc. The data you are seeing are details since that first insert into the cache.\"))\n",
    "stmt_top10_byixref_df=stmt_top10_byixref.DataFrame()\n",
    "stmt_top10_byixref_df.columns=stmt_top10_byixref_df.columns.str.upper()\n",
    "stmt_top10_byixref_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41674d29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2f2ac3",
   "metadata": {},
   "source": [
    "## Database Wait Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql db_timespent << select * \n",
    "    from table(mon_get_database(-2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04582074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=db_timespent.DataFrame()\n",
    "df.columns= df.columns.str.upper()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: 'df' is a DataFrame that has time series data from MON_GET_DATABASE.\n",
    "# Because the Wait Times are cumulative, I really only care about the most \n",
    "# recent entry in 'df'.\n",
    "#\n",
    "# Get the index of the last row, and build a dictionary with with all of the \n",
    "# wait time elements:\n",
    "i = 0\n",
    "ix = {'AGENT_WAIT_TIME': df['AGENT_WAIT_TIME'][i],\n",
    "      'WLM_QUEUE_TIME_TOTAL': df['WLM_QUEUE_TIME_TOTAL'][i],\n",
    "      'LOCK_WAIT_TIME':  df['LOCK_WAIT_TIME'][i], \n",
    "      'LOG_BUFFER_WAIT_TIME': df['LOG_BUFFER_WAIT_TIME'][i],\n",
    "      'LOG_DISK_WAIT_TIME': df['LOG_DISK_WAIT_TIME'][i],\n",
    "      'TCPIP_RECV_WAIT_TIME': df['TCPIP_RECV_WAIT_TIME'][i],\n",
    "      'TCPIP_SEND_WAIT_TIME': df['TCPIP_SEND_WAIT_TIME'][i],\n",
    "      'IPC_RECV_WAIT_TIME': df['IPC_RECV_WAIT_TIME'][i],\n",
    "      'IPC_SEND_WAIT_TIME': df['IPC_SEND_WAIT_TIME'][i],\n",
    "      'FCM_RECV_WAIT_TIME': df['FCM_RECV_WAIT_TIME'][i],\n",
    "      'FCM_SEND_WAIT_TIME': df['FCM_SEND_WAIT_TIME'][i],\n",
    "      'AUDIT_SUBSYSTEM_WAIT_TIME': df['AUDIT_SUBSYSTEM_WAIT_TIME'][i],\n",
    "      'AUDIT_FILE_WRITE_WAIT_TIME': df['AUDIT_FILE_WRITE_WAIT_TIME'][i],\n",
    "      'DIAGLOG_WRITE_WAIT_TIME': df['DIAGLOG_WRITE_WAIT_TIME'][i],\n",
    "      'POOL_READ_TIME': df['POOL_READ_TIME'][i],\n",
    "      'POOL_WRITE_TIME': df['POOL_WRITE_TIME'][i],\n",
    "      'DIRECT_READ_TIME': df['DIRECT_READ_TIME'][i],\n",
    "      'DIRECT_WRITE_TIME': df['DIRECT_WRITE_TIME'][i],\n",
    "      'EVMON_WAIT_TIME': df['EVMON_WAIT_TIME'][i],\n",
    "      'TOTAL_EXTENDED_LATCH_WAIT_TIME': df['TOTAL_EXTENDED_LATCH_WAIT_TIME'][i],\n",
    "      'PREFETCH_WAIT_TIME': df['PREFETCH_WAIT_TIME'][i],\n",
    "      'COMM_EXIT_WAIT_TIME': df['COMM_EXIT_WAIT_TIME'][i],\n",
    "      'IDA_SEND_WAIT_TIME': df['IDA_SEND_WAIT_TIME'][i],\n",
    "      'IDA_RECV_WAIT_TIME': df['IDA_RECV_WAIT_TIME'][i],\n",
    "      'CF_WAIT_TIME': df['CF_WAIT_TIME'][i],\n",
    "      'RECLAIM_WAIT_TIME': df['RECLAIM_WAIT_TIME'][i],\n",
    "      'SPACEMAPPAGE_RECLAIM_WAIT_TIME': df['SPACEMAPPAGE_RECLAIM_WAIT_TIME'][i]}\n",
    "\n",
    "# Convert the dictionary into a new DataFrame.\n",
    "myx=pd.DataFrame.from_dict(ix, orient='index')\n",
    "\n",
    "# Calcuate the percentage of overall wait for each value.\n",
    "total=myx[0].sum()\n",
    "myx['PCT'] = myx.apply(lambda x: x[0]/total, axis=1)\n",
    "\n",
    "# Filter out wait elements that have <= 0.5% wait time), to avoid having \n",
    "# 27 slices of pie, most of which are tiny slivers\n",
    "myx = myx[myx['PCT'] >= 0.005]\n",
    "\n",
    "# Set up the graph\n",
    "display(Markdown(\"#### Database Wait Time\"))\n",
    "xlabel=myx.index.tolist()\n",
    "yname=myx.columns.values[0]\n",
    "plt = myx.plot(kind='pie',y=yname,labels=xlabel,figsize=[5,5],autopct='%0.1f%%')\n",
    "plt.get_legend().remove()\n",
    "plt.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e29c74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c17b64",
   "metadata": {},
   "source": [
    "## Locking Analysis (Past 24 Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql lock_event_24 <<\n",
    "SELECT\n",
    "  SUBSTR(EVENT_TYPE,1,18) AS EVENT_TYPE,\n",
    "  COUNT(*)/2 AS COUNT\n",
    "FROM DBAMON.LOCK_EVENT\n",
    "WHERE EVENT_TIMESTAMP >= CURRENT TIMESTAMP - 24 hours\n",
    "GROUP BY EVENT_TYPE \n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"####  Locking Events - Past 24 hours\"))\n",
    "lock_event_24_df=lock_event_24.DataFrame()\n",
    "lock_event_24_df.columns=lock_event_24_df.columns.str.upper()\n",
    "lock_event_24_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ca40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql lock_event_bytable_24 <<\n",
    "SELECT\n",
    "  SUBSTR(LP.TABLE_SCHEMA,1,18) AS TABLE_SCHEMA,\n",
    "  SUBSTR(LP.TABLE_NAME,1,30) AS TABLE_NAME,\n",
    "  SUBSTR(LE.EVENT_TYPE,1,18) AS LOCK_EVENT,\n",
    "  COUNT(*)/2 AS COUNT\n",
    "FROM DBAMON.LOCK_PARTICIPANTS LP, DBAMON.LOCK_EVENT LE\n",
    "WHERE LP.XMLID=LE.XMLID \n",
    "\tAND EVENT_TIMESTAMP >= CURRENT TIMESTAMP - 24 HOURS\n",
    "\tAND NOT (LP.TABLE_SCHEMA IS NULL OR LP.TABLE_SCHEMA IS NULL)\n",
    "GROUP BY LP.TABLE_SCHEMA, LP.TABLE_NAME, LE.EVENT_TYPE\n",
    "ORDER BY LP.TABLE_SCHEMA, LP.TABLE_NAME, LE.EVENT_TYPE \n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"####  Locking Events By Table - Past 24 hours\"))\n",
    "lock_event_bytable_24_df=lock_event_bytable_24.DataFrame()\n",
    "lock_event_bytable_24_df.columns=lock_event_bytable_24_df.columns.str.upper()\n",
    "lock_event_bytable_24_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b3afb",
   "metadata": {},
   "source": [
    "## Security and Access "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql public_auth <<\n",
    "SELECT DISTINCT GRANTEE, GRANTEETYPE, 'DATABASE CONNECT AUTHORITY DETECTED' AS ACCESS_LEVEL \n",
    "   FROM SYSCAT.DBAUTH \n",
    "   WHERE GRANTEE='PUBLIC' AND CONNECTAUTH='Y'\n",
    " UNION\n",
    "SELECT DISTINCT GRANTEE, GRANTEETYPE, 'TABLE LEVEL AUTHORITY DETECTED' AS ACCESS_LEVEL \n",
    "   FROM SYSCAT.TABAUTH WHERE GRANTEE='PUBLIC'\n",
    "   AND TABSCHEMA NOT LIKE 'SYS%'\n",
    "   AND (CONTROLAUTH='Y' OR ALTERAUTH='Y' OR DELETEAUTH='Y' \n",
    "   OR DELETEAUTH='Y' OR INDEXAUTH='Y' OR INSERTAUTH='Y' \n",
    "   OR REFAUTH='Y' OR SELECTAUTH='Y' OR UPDATEAUTH='Y')\n",
    " UNION\n",
    "SELECT DISTINCT GRANTEE, GRANTEETYPE, 'PACKAGE LEVEL AUTHORITY DETECTED' AS ACCESS_LEVEL FROM SYSCAT.PACKAGEAUTH WHERE GRANTEE='PUBLIC' AND CONTROLAUTH='Y'\n",
    " UNION\n",
    "SELECT DISTINCT GRANTEE, GRANTEETYPE, 'SCHEMA LEVEL AUTHORITY DETECTED' AS ACCESS_LEVEL FROM SYSCAT.SCHEMAAUTH WHERE GRANTEE='PUBLIC'\n",
    "   AND SCHEMANAME NOT LIKE 'SYS%'\n",
    "   AND (ALTERINAUTH='Y' OR CREATEINAUTH='Y' OR DROPINAUTH='Y' \n",
    "   OR SELECTINAUTH='Y' OR INSERTINAUTH='Y' OR UPDATEINAUTH='Y' \n",
    "   OR DELETEINAUTH='Y' OR EXECUTEINAUTH='Y' OR SCHEMAADMAUTH='Y' \n",
    "   OR ACCESSCTRLAUTH='Y' OR DATAACCESSAUTH='Y' OR LOADAUTH='Y')\n",
    "ORDER BY GRANTEE, GRANTEETYPE, ACCESS_LEVEL\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"####  PUBLIC Access & Authorities\"))\n",
    "display(Markdown(\"Tip: Sometimes PUBLIC access is found and is OK (i.e. ability to bind). What we are looking for is the ability for PUBLIC to connect and read or update sensitive information.\"))\n",
    "public_auth_df=public_auth.DataFrame()\n",
    "public_auth_df.columns=public_auth_df.columns.str.upper()\n",
    "public_auth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b38a40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690ed79",
   "metadata": {},
   "source": [
    "## Error Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4674ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql error_72hours <<\n",
    "SELECT \n",
    " TIMESTAMP, \n",
    " DBNAME,\n",
    " APPL_ID, \n",
    " LEVEL, \n",
    " IMPACT, \n",
    " SUBSTR(MSG,1, 70) AS MSG \n",
    "FROM TABLE (PD_GET_DIAG_HIST( 'MAIN', 'D', '', NULL, NULL) ) AS T \n",
    "WHERE LEVEL IN ('C','S','E') \n",
    "      AND MSG IS NOT NULL \n",
    "      AND TIMESTAMP >= current timestamp - 72 HOURS\n",
    "ORDER BY TIMESTAMP DESC\n",
    "WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9afd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Error Log - Past 72 hours\"))\n",
    "display(Markdown(\"Data below is not exhaustive. This is showing CRITICAL, SEVERE, or ERROR message in the db2diag.log. \"))\n",
    "error_72hours_df=error_72hours.DataFrame()\n",
    "error_72hours_df.columns=error_72hours_df.columns.str.upper()\n",
    "error_72hours_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d3f79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb656cbe",
   "metadata": {},
   "source": [
    "## Credit & References\n",
    "\n",
    "- Ragu on Tech: [Db2 Finding Top 10 Most Active Tables](https://www.raghu-on-tech.com/2020/02/29/db2-finding-top-10-most-active-tables/)\n",
    "- Xtivia: [Index Read Efficiency a KPI for Db2](https://www.virtual-dba.com/blog/index-read-efficiency-db2/)\n",
    "- Datageek: [Db2 Table Scans](https://datageek.blog/en/2012/11/28/db2-table-scans/)\n",
    "- DBI Software Blog: [Table Read I/O and Overflows](https://www.dbisoftware.com/blog/db2_performance.php?id=116)\n",
    "- Xtivia: [Index Read Efficiency - A KPI for Db2](https://www.virtual-dba.com/blog/index-read-efficiency-db2/)\n",
    "- Datageek: [Boost Your Performance – (IREF) Index Read Efficiency](https://datageek.blog/en/2014/03/17/boost-your-performance-iref-index-read-efficiency/)\n",
    "- Use the Index Luke: [More Indexes, Slower Insert](https://use-the-index-luke.com/sql/dml/insert)\n",
    "- Statsology: [How to Create a Pie Chart from Pandas Dataframe](https://www.statology.org/pandas-pie-chart/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
